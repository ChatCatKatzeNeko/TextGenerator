{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = open(\"theLordOfTheRings.txt\", 'r')\n",
    "data = txt.read()\n",
    "data = data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(data)\n",
    "words = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_break_down = [word_tokenize(sentence) for sentence in sentences] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_dim = 300 # length of each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences_break_down,\n",
    "                 sg=1,\n",
    "                 size=emb_dim,\n",
    "                 window=3,\n",
    "                 alpha=0.0005,\n",
    "                 min_count=1,\n",
    "                 workers=8,\n",
    "                 batch_words=1500\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9870\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(list(model.wv.vocab))\n",
    "print(vocab_size)\n",
    "\n",
    "vocab = list(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37466189, 54575500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences_break_down, total_words=vocab_size, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boromir', 0.9888407588005066),\n",
       " ('aragorn', 0.9885234236717224),\n",
       " ('gimli', 0.9864516258239746),\n",
       " ('legolas', 0.9828614592552185),\n",
       " ('pippin', 0.9820834994316101),\n",
       " ('sam', 0.9729862213134766),\n",
       " ('strider', 0.9723973274230957),\n",
       " ('haldir', 0.9661816954612732),\n",
       " ('tom', 0.9613646864891052),\n",
       " ('butterbur', 0.9604867696762085)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=\"merry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idWordsDict = dict((Id, word) for Id, word in enumerate(vocab))\n",
    "wordsIdDict = dict((word, Id) for Id, word in enumerate(vocab))\n",
    "idVectDict = dict((Id, vect.reshape(1,len(vect))) for Id, vect in enumerate(model.wv[vocab]))   # length of the 3 dictionaries: 10883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample a word from the distribution of a predicted probability\n",
    "# \"prediction\" is of shape (1, vocab_size)\n",
    "def sample(prediction):\n",
    "    r = random.uniform(0,1)\n",
    "    s = 0\n",
    "    word_id = 0\n",
    "    for i in range(len(prediction[0])):\n",
    "        s += prediction[0,i]\n",
    "        if s >= r:\n",
    "            word_id = i\n",
    "            break\n",
    "    return word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "section_len = 12 # group words as a section\n",
    "skip = 10\n",
    "sections = []\n",
    "labels = []\n",
    "for i in range(0, len(words)-section_len, skip):\n",
    "    sections.append(words[i:i+section_len])\n",
    "    labels.append(words[i+section_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_sections = len(labels)\n",
    "\n",
    "history_words = np.zeros((nb_sections, section_len, emb_dim))\n",
    "current_words = np.zeros((nb_sections, vocab_size))\n",
    "\n",
    "for i in range(nb_sections):\n",
    "    history_words[i,:,:] = model.wv[sections[i]]\n",
    "    current_words[i,wordsIdDict[labels[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43659, 10, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43659, 9870)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gru generating network settings\n",
    "batch_size = 400\n",
    "hidden_nodes = 2048\n",
    "nb_iter = 3000    # this is NOT the nb of epochs, it is the nb of batches to run in the training process\n",
    "lr = 0.002\n",
    "proba = 0.5\n",
    "nb_layers = 2\n",
    "log_every = 50\n",
    "checkpoint_every = 100\n",
    "checkpoint_directory = 'checkpts2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create checkpoints dir.\n",
    "if tf.gfile.Exists(checkpoint_directory):\n",
    "    tf.gfile.DeleteRecursively(checkpoint_directory)\n",
    "tf.gfile.MkDir(checkpoint_directory)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    '''\n",
    "    placeholders\n",
    "    '''\n",
    "    train_data = tf.placeholder(tf.float32, [batch_size, section_len, emb_dim])\n",
    "    train_labels = tf.placeholder(tf.float32, [batch_size, vocab_size])\n",
    "    \n",
    "    test_data = tf.placeholder(tf.float32, shape=[1,section_len, emb_dim])\n",
    "    \n",
    "    keep_proba = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    define global step and GRU-Dropout cell\n",
    "    '''\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    def GRU_Dropout(nb_hidden_nodes, keep_prob):\n",
    "        cell = rnn.GRUCell(nb_hidden_nodes)\n",
    "        cell = rnn.DropoutWrapper(cell,output_keep_prob=keep_prob)\n",
    "        return cell\n",
    "    \n",
    "    \n",
    "               \n",
    "    '''\n",
    "    GRU_Dropout layer feed forward\n",
    "    '''\n",
    "    # 2 layers: [GRU , Dropout] -> [GRU , Dropout]\n",
    "    stacked_GRUs = rnn.MultiRNNCell([GRU_Dropout(hidden_nodes, keep_proba) for _ in range(nb_layers)],\n",
    "                                    state_is_tuple=True)\n",
    "    init_state = stacked_GRUs.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "    state = init_state\n",
    "    output = tf.zeros([batch_size, hidden_nodes])\n",
    "    for i in range(section_len):\n",
    "        output, state = stacked_GRUs(train_data[:,i,:],state)\n",
    "    \n",
    "    '''\n",
    "    fully connected layer feed forward\n",
    "    ''' \n",
    "    w = tf.Variable(tf.truncated_normal([hidden_nodes, vocab_size], -0.3, 0.3))\n",
    "    b = tf.Variable(tf.zeros([vocab_size]))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    train\n",
    "    '''\n",
    "    predictions = tf.matmul(output, w) + b\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels, logits=predictions))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    test\n",
    "    '''\n",
    "    test_state = stacked_GRUs.zero_state(1, dtype=tf.float32)\n",
    "    test_output = tf.Variable(tf.zeros([section_len, hidden_nodes]))\n",
    "    \n",
    "\n",
    "    for i in range(section_len):\n",
    "        test_output, test_state = stacked_GRUs(test_data[:,i,:], test_state)\n",
    "        \n",
    "        \n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_output, w) + b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9X9xFVoBzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6aef86a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    offset = 0\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    hist_len = len(history_words)\n",
    "    \n",
    "    # for each training step\n",
    "    for step in range(nb_iter):\n",
    "        \n",
    "        # starts off as 0\n",
    "        offset = offset % hist_len\n",
    "        \n",
    "        # calculate batch data and labels to feed model iteratively\n",
    "        if offset <= (hist_len - batch_size):\n",
    "            # first parts\n",
    "            batch_data = history_words[offset: offset + batch_size]\n",
    "            batch_labels = current_words[offset: offset + batch_size]\n",
    "            offset += batch_size\n",
    "\n",
    "        else:\n",
    "            # the last part\n",
    "            to_add = batch_size - (hist_len - offset)\n",
    "            batch_data = np.concatenate((history_words[offset: hist_len], history_words[0: to_add]))\n",
    "            batch_labels = np.concatenate((current_words[offset: hist_len], current_words[0: to_add]))\n",
    "            offset = to_add\n",
    "        \n",
    "        _, training_loss = sess.run([optimizer, loss], feed_dict={train_data: batch_data, train_labels: batch_labels, \n",
    "                                                                  keep_proba: proba})\n",
    "        losses.append(training_loss)\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print('training loss at step %d: %.3f (%s)' % (step, training_loss, datetime.datetime.now()))\n",
    "\n",
    "            if step % checkpoint_every == 0:\n",
    "                saver.save(sess, checkpoint_directory + '/model', global_step=step)\n",
    "    print('training loss at step %d: %.2f (%s)' % (nb_iter, training_loss, datetime.datetime.now()))\n",
    "\n",
    "    plt.plot(np.arange(nb_iter), losses)\n",
    "    plt.title('Learning Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_start = 'gandalf was reading the riddle written on the stone in elvish and has understood nothing but '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpts2/model-1900\n",
      "gandalf was reading the riddle written on the stone in elvish and has understood nothing but 'strider to strands fleeing ' said gandalf , and pippin looked out . 'now soon did hear what if them , ' said gandalf . 'neither have been the fortnight place in the minds of men . the return mountains mountains they windings grows against the dark and naked ; and the lingering grew the eastern in the night . the river was fetched of snow in the night , and without the secrecy . ’ he said . 'you must you have been here , but come , break may day gimli , and the others have come to look on the ground . we can send telling on again . i can get in perhaps the land , and we want get in hobbiton , and the paths in the mountains above the wild land in the return ; glistening of black folk , lantern-light shone bofur of the men , and those for them movements to ground as long in the flies . it was weary well hale , elrond was sinking of eastern . stones nine lay his snow sinking , and the flat were nuzzled , to the snow until they were steadily over the \n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    #init graph, load model\n",
    "    tf.global_variables_initializer().run()\n",
    "    model_tf = tf.train.latest_checkpoint(checkpoint_directory)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_tf)\n",
    "\n",
    "    #set input variable to generate chars from\n",
    "    #reset_test_state.run() \n",
    "    test_generated = test_start\n",
    "    \n",
    "    tokenized_start = word_tokenize(test_start)\n",
    "    test_X = model.wv[tokenized_start[-section_len:]]\n",
    "\n",
    "    generated_len = 200\n",
    "    counter = 1\n",
    "    while counter <= generated_len:\n",
    "        # Attention: in the test phase, reset the keep_proba to 1 \n",
    "        prediction = sess.run(test_prediction, feed_dict={test_data: test_X.reshape((1,section_len,emb_dim)), \n",
    "                                                          keep_proba: 1.0})\n",
    "        word_id = sample(prediction)\n",
    "        \n",
    "        next_word = idWordsDict[word_id]\n",
    "        test_generated += (next_word + ' ')\n",
    "        \n",
    "        test_X = np.concatenate([test_X, idVectDict[word_id]], axis=0)[1:]\n",
    "        \n",
    "        counter += 1\n",
    "         \n",
    "    print(test_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
